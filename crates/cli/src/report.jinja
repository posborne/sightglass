<!doctype html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <title>Sightglass Benchmark Results</title>
        <meta name="description" content="Sightglass Benchmark Results Visualization">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <script src="https://cdn.jsdelivr.net/npm/vega@6"></script>
        <script src="https://cdn.jsdelivr.net/npm/vega-lite@6"></script>
        <script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script>
        {% for benchmark in stats.benchmarks %}
        <script type="application/json" id="vega-lite-{{ benchmark.chart.id }}">
            {{ benchmark.chart.json }}
        </script>
        {% endfor %}
        <style>
            .slower {
                background: lightcoral;
                font-weight: bold;
            }

            .faster {
                background: lightgreen;
                font-weight: bold;
            }

            .inconsistent {
                background: lightgray;
            }

            .controls {
                background: #f5f5f5;
                padding: 15px;
                margin: 20px 0;
                border-radius: 5px;
                border: 1px solid #ddd;
            }

            .control-group {
                display: inline-block;
                margin-right: 20px;
                vertical-align: top;
            }

            .control-group label {
                display: block;
                font-weight: bold;
                margin-bottom: 5px;
            }

            .hidden-benchmark {
                display: none;
            }

            .hidden-row {
                display: none;
            }
        </style>
    </head>
    <body>
        <h1>Sightglass Benchmark Results</h1>
        <div>
            <span style="font-weight:bold">Key:</span>
            <span class="inconsistent">High CV (> 5%) -- Noisy/Flaky Test</span>
            <span class="slower">Statistically Significantly Slower</span>
            <span class="faster">Statistically Significantly Faster</span>
            <span>No highlighting = No significant difference</span>
        </div>
        <div>
            Results show statistical significance based on <a href="#effect-size-methodology">effect size analysis</a> with 95% confidence intervals (α = 0.05).
            CV is the <a href="https://en.wikipedia.org/wiki/Coefficient_of_variation">Coefficient of Variation</a>, indicating measurement consistency.
        </div>

        <div class="controls">
            <div class="control-group">
                <label>
                    <input type="checkbox" id="significant-only" onchange="updateFilters()">
                    Show only statistically significant results
                </label>
            </div>
            <div class="control-group">
                <label>
                    <input type="checkbox" id="hide-noisy" onchange="updateFilters()">
                    Hide noisy tests (CV > 5%)
                </label>
            </div>
            <div class="control-group">
                <span id="visible-benchmarks"></span>
            </div>
        </div>

        <table style="padding-top:20px" id="results-table">
            <thead>
                <tr>
                    <th scope="col">Benchmark</th>
                    <th scope="col">CV%</th>
                    <th scope="col">{{ stats.baseline_engine }} (baseline)</th>
                    {% for engine in stats.benchmarks[0].stats_by_engine %}
                        {% if engine != stats.baseline_engine %}
                        <th scope="col">{{ engine }}</th>
                        {% endif %}
                    {% endfor %}
                </tr>
            </thead>
            <tbody>
                {% for benchmark in stats.benchmarks %}
                {% set bstats = benchmark.baseline_stats %}
                {% set has_significant = namespace(value=false) %}
                {% set best_confidence = namespace(value=1.0) %}
                {% for engine, pstats in benchmark.stats_by_engine|items %}
                    {% if pstats.relative_stats and pstats.relative_stats.is_significant %}
                        {% set has_significant.value = true %}
                        {% if pstats.significance_level < best_confidence.value %}
                            {% set best_confidence.value = pstats.significance_level %}
                        {% endif %}
                    {% endif %}
                {% endfor %}
                <tr class="benchmark-row"
                    data-has-significant="{{ has_significant.value|lower }}"
                    data-baseline-cv="{{ bstats.cv }}"
                    data-benchmark-name="{{ benchmark.name }}">
                    <td><a href="#{{ benchmark.name }}">{{ benchmark.name }}</a></td>
                    {# CV% column #}
                    {% set bstats = benchmark.stats_by_engine[stats.baseline_engine] %}
                    {% set cv_class = "inconsistent" if bstats.cv > 5 else "" %}
                    <td class="{{ cv_class }}">{{ bstats.cv|floatfmt }}%</td>
                    {# Baseline column without CV #}
                    <td class="cycle-count">{{ bstats.p25|intfmt }}</td>
                    {# Then show other engines #}
                    {% for engine, pstats in benchmark.stats_by_engine|items %}
                        {% if pstats.relative_stats %}
                        {% set rel = pstats.relative_stats %}
                        {% set class = "slower" if rel.is_significant and rel.speedup_ratio > 1 else "faster" if rel.is_significant and rel.speedup_ratio < 1 else "" %}
                        {% if rel.is_significant %}
                            {% if rel.speedup_ratio < 1 %}
                                {% set pct_faster = ((1 - rel.speedup_ratio) * 100)|floatfmt %}
                                <td class="{{ class }}">{{ pct_faster }}% faster</td>
                            {% else %}
                                {% set pct_slower = ((rel.speedup_ratio - 1) * 100)|floatfmt %}
                                <td class="{{ class }}">{{ pct_slower }}% slower</td>
                            {% endif %}
                        {% else %}
                            <td>No significant difference</td>
                        {% endif %}
                        {% endif %}
                    {% endfor %}
                </tr>
                {% endfor %}
            </tbody>
        </table>

        <div id="benchmark-details">
            {% for benchmark in stats.benchmarks %}
            {% set bstats = benchmark.baseline_stats %}
            {% set has_significant = namespace(value=false) %}
            {% for engine, pstats in benchmark.stats_by_engine|items %}
                {% if pstats.relative_stats and pstats.relative_stats.is_significant %}
                    {% set has_significant.value = true %}
                {% endif %}
            {% endfor %}
            <div class="benchmark-detail"
                 data-has-significant="{{ has_significant.value|lower }}"
                 data-baseline-cv="{{ bstats.cv }}"
                 data-benchmark-name="{{ benchmark.name }}">
                <h2 id="{{benchmark.name}}">{{ benchmark.name }}</h2>
            <ul>
                <li><strong>Baseline:</strong> <span class="cycle-count">{{ bstats.mean|intfmt }}</span> cycles (<span {% if bstats.cv > 5 %}class="inconsistent"{% endif %}>CV: {{ bstats.cv|floatfmt }}%</span>)</li>
                {% for engine, pstats in benchmark.stats_by_engine|items %}
                    {% if pstats.relative_stats %}
                        {% set rel = pstats.relative_stats %}
                        {% if rel.is_significant %}
                            {% set class = "slower" if rel.speedup_ratio > 1 else "faster" %}
                            {% if rel.speedup_ratio < 1 %}
                                {% set pct_faster = ((1 - rel.speedup_ratio) * 100)|floatfmt %}
                                <li>{{ engine }}: <span class="{{ class }}">{{ pct_faster }}% faster</span>
                            {% else %}
                                {% set pct_slower = ((rel.speedup_ratio - 1) * 100)|floatfmt %}
                                <li>{{ engine }}: <span class="{{ class }}">{{ pct_slower }}% slower</span>
                            {% endif %}
                            {% if rel.confidence_interval_half_width %}
                                (95% confident with ±{{ rel.confidence_interval_half_width|floatfmt }} cycles margin)
                            {% endif %}
                            (CV: {{ pstats.cv|floatfmt }}%)</li>
                        {% else %}
                            <li>{{ engine }}: No significant difference ({{ rel.p25_delta_pct|floatfmt }}%) (CV: {{ pstats.cv|floatfmt }}%)</li>
                        {% endif %}
                    {% endif %}
                {% endfor %}
            </ul>
            <div id="viz-{{ benchmark.chart.id }}"></div>
            </div>
            {% endfor %}
        </div>

        <script type="text/javascript">
         function renderViz(chart_id) {
           let vl_text = document.getElementById(`vega-lite-${chart_id}`).textContent;
           let vl_data = JSON.parse(vl_text);
           vegaEmbed(`#viz-${chart_id}`, vl_data);
         }
         {% for benchmark in stats.benchmarks %}
         renderViz("{{ benchmark.chart.id }}");
         {% endfor %}

         // Simple data for filtering - most data is now in HTML data attributes

         function updateFilters() {
             const significantOnly = document.getElementById('significant-only').checked;
             const hideNoisy = document.getElementById('hide-noisy').checked;

             const rows = document.querySelectorAll('.benchmark-row');
             const details = document.querySelectorAll('.benchmark-detail');
             let visibleCount = 0;

             // Filter table rows and benchmark details
             rows.forEach((row, index) => {
                 const hasSignificant = row.dataset.hasSignificant === 'true';
                 const baselineCv = parseFloat(row.dataset.baselineCv);

                 let shouldShow = true;

                 // Apply noise filter
                 if (hideNoisy && baselineCv > 5) {
                     shouldShow = false;
                 }

                 // Apply significance filter
                 if (significantOnly && !hasSignificant) {
                     shouldShow = false;
                 }

                 // Show/hide row and corresponding detail
                 row.style.display = shouldShow ? '' : 'none';
                 if (details[index]) {
                     details[index].style.display = shouldShow ? '' : 'none';
                 }

                 if (shouldShow) visibleCount++;
             });

             // Update counter
             document.getElementById('visible-benchmarks').textContent =
                 `Showing ${visibleCount} of ${rows.length} benchmarks`;
         }

         // Format numbers with commas using toLocaleString()
         function formatCycleCounts() {
             document.querySelectorAll('.cycle-count').forEach(element => {
                 const num = parseInt(element.textContent.trim());
                 if (!isNaN(num)) {
                     element.textContent = num.toLocaleString();
                 }
             });
         }

         // Initialize filters and formatting on page load
         document.addEventListener('DOMContentLoaded', function() {
             updateFilters();
             formatCycleCounts();
         });
        </script>

        <div id="effect-size-methodology" style="margin-top: 40px; padding: 20px; background: #f9f9f9; border-radius: 5px;">
            <h2>Statistical Methodology</h2>
            <p>
                This report follows the <a href="https://github.com/bytecodealliance/rfcs/blob/main/accepted/benchmark-suite.md" target="_blank">Bytecode Alliance RFC standards</a>
                for statistically rigorous performance analysis, using <strong>effect size analysis</strong> with confidence intervals
                rather than simple averages or visual comparisons.
            </p>
            <p>
                <strong>Statistical Foundation:</strong> Built on Student's t-test principles for comparing two means, with Behrens-Fisher analysis
                for unequal variances. This provides confidence intervals like "95% confident that engine A is 1.05x to 1.15x faster than engine B"
                or "there is no statistically significant difference in performance between the engines".
            </p>
            <p><strong>This approach quantifies both:</strong></p>
            <ul>
                <li><strong>Statistical significance</strong>: Whether the performance difference is likely real (not due to measurement noise)</li>
                <li><strong>Practical significance</strong>: The magnitude of the performance difference with confidence bounds</li>
            </ul>
            <p>
                <strong>Key Metrics:</strong> Analysis focuses on execution cycles as the primary metric, with coefficient of variation (CV)
                used to assess measurement reliability. Tests with CV > 5% are flagged as potentially noisy.
            </p>
            <p>
                <strong>References:</strong>
                <a href="https://github.com/bytecodealliance/rfcs/blob/main/accepted/benchmark-suite.md" target="_blank">Benchmark Suite RFC</a> |
                <a href="https://github.com/bytecodealliance/sightglass#benchmarking-with-sightglass" target="_blank">Sightglass Documentation</a>
            </p>
        </div>
    </body>
</html>
